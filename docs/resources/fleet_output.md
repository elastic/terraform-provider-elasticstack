---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "elasticstack_fleet_output Resource - terraform-provider-elasticstack"
subcategory: "Fleet"
description: |-
  Creates a new Fleet Output.
---

# elasticstack_fleet_output (Resource)

Creates a new Fleet Output.

## Example Usage

### Basic output

```terraform
provider "elasticstack" {
  kibana {}
}

resource "elasticstack_fleet_output" "test_output" {
  name = "Test Output"
  type = "elasticsearch"
  config_yaml = yamlencode({
    "ssl.verification_mode" : "none"
  })
  default_integrations = false
  default_monitoring   = false
  hosts = [
    "https://elasticsearch:9200"
  ]
}
```

### Basic Kafka output

```terraform
terraform {
  required_providers {
    elasticstack = {
      source  = "elastic/elasticstack"
      version = "~> 0.11"
    }
  }
}

provider "elasticstack" {
  elasticsearch {}
  kibana {}
}

# Basic Kafka Fleet Output
resource "elasticstack_fleet_output" "kafka_basic" {
  name                 = "Basic Kafka Output"
  output_id            = "kafka-basic-output"
  type                 = "kafka"
  default_integrations = false
  default_monitoring   = false

  hosts = [
    "kafka:9092"
  ]

  # Basic Kafka configuration
  kafka = {
    auth_type     = "user_pass"
    username      = "kafka_user"
    password      = "kafka_password"
    topic         = "elastic-beats"
    partition     = "hash"
    compression   = "gzip"
    required_acks = 1

    headers = [
      {
        key   = "environment"
        value = "production"
      }
    ]
  }
}
```

### Advanced Kafka output

```terraform
terraform {
  required_providers {
    elasticstack = {
      source  = "elastic/elasticstack"
      version = "~> 0.11"
    }
  }
}

provider "elasticstack" {
  elasticsearch {}
  kibana {}
}

# Advanced Kafka Fleet Output with SSL authentication
resource "elasticstack_fleet_output" "kafka_advanced" {
  name                 = "Advanced Kafka Output"
  output_id            = "kafka-advanced-output"
  type                 = "kafka"
  default_integrations = false
  default_monitoring   = false

  hosts = [
    "kafka1:9092",
    "kafka2:9092",
    "kafka3:9092"
  ]

  # Advanced Kafka configuration
  kafka = {
    auth_type      = "ssl"
    topic          = "elastic-logs"
    partition      = "round_robin"
    compression    = "snappy"
    required_acks  = -1
    broker_timeout = 10
    timeout        = 30
    version        = "2.6.0"
    client_id      = "elastic-beats-client"

    # Custom headers for message metadata
    headers = [
      {
        key   = "datacenter"
        value = "us-west-1"
      },
      {
        key   = "service"
        value = "beats"
      },
      {
        key   = "environment"
        value = "production"
      }
    ]

    # Hash-based partitioning
    hash = {
      hash   = "host.name"
      random = false
    }

    # SASL configuration
    sasl = {
      mechanism = "SCRAM-SHA-256"
    }
  }

  # SSL configuration (reusing common SSL block)
  ssl = {
    certificate_authorities = [
      file("${path.module}/ca.crt")
    ]
    certificate = file("${path.module}/client.crt")
    key         = file("${path.module}/client.key")
  }

  # Additional YAML configuration for advanced settings
  config_yaml = yamlencode({
    "ssl.verification_mode"   = "full"
    "ssl.supported_protocols" = ["TLSv1.2", "TLSv1.3"]
    "max.message.bytes"       = 1000000
  })
}

# Example showing round-robin partitioning with event grouping
resource "elasticstack_fleet_output" "kafka_round_robin" {
  name                 = "Kafka Round Robin Output"
  output_id            = "kafka-round-robin-output"
  type                 = "kafka"
  default_integrations = false
  default_monitoring   = false

  hosts = ["kafka:9092"]

  kafka = {
    auth_type   = "none"
    topic       = "elastic-metrics"
    partition   = "round_robin"
    compression = "lz4"

    round_robin = [
      {
        group_events = 100
      }
    ]
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `name` (String) The name of the output.
- `type` (String) The output type.

### Optional

- `ca_sha256` (String) Fingerprint of the Elasticsearch CA certificate.
- `ca_trusted_fingerprint` (String) Fingerprint of trusted CA.
- `config_yaml` (String, Sensitive) Advanced YAML configuration. YAML settings here will be added to the output section of each agent policy.
- `default_integrations` (Boolean) Make this output the default for agent integrations.
- `default_monitoring` (Boolean) Make this output the default for agent monitoring.
- `hosts` (List of String) A list of hosts.
- `kafka` (Attributes) Kafka-specific configuration. (see [below for nested schema](#nestedatt--kafka))
- `output_id` (String) Unique identifier of the output.
- `space_ids` (List of String) The Kibana space IDs where this output is available. When set, the output will be created and managed within the specified space.
- `ssl` (Attributes) SSL configuration. (see [below for nested schema](#nestedatt--ssl))

### Read-Only

- `id` (String) The ID of this resource.

<a id="nestedatt--kafka"></a>
### Nested Schema for `kafka`

Optional:

- `auth_type` (String) Authentication type for Kafka output.
- `broker_timeout` (Number) Kafka broker timeout.
- `client_id` (String) Kafka client ID.
- `compression` (String) Compression type for Kafka output.
- `compression_level` (Number) Compression level for Kafka output.
- `connection_type` (String) Connection type for Kafka output.
- `hash` (Attributes) Hash configuration for Kafka partition. (see [below for nested schema](#nestedatt--kafka--hash))
- `headers` (Attributes List) Headers for Kafka messages. (see [below for nested schema](#nestedatt--kafka--headers))
- `key` (String) Key field for Kafka messages.
- `partition` (String) Partition strategy for Kafka output.
- `password` (String, Sensitive) Password for Kafka authentication.
- `random` (Attributes) Random configuration for Kafka partition. (see [below for nested schema](#nestedatt--kafka--random))
- `required_acks` (Number) Number of acknowledgments required for Kafka output.
- `round_robin` (Attributes) Round robin configuration for Kafka partition. (see [below for nested schema](#nestedatt--kafka--round_robin))
- `sasl` (Attributes) SASL configuration for Kafka authentication. (see [below for nested schema](#nestedatt--kafka--sasl))
- `timeout` (Number) Timeout for Kafka output.
- `topic` (String) Kafka topic.
- `username` (String) Username for Kafka authentication.
- `version` (String) Kafka version.

<a id="nestedatt--kafka--hash"></a>
### Nested Schema for `kafka.hash`

Optional:

- `hash` (String) Hash field.
- `random` (Boolean) Use random hash.


<a id="nestedatt--kafka--headers"></a>
### Nested Schema for `kafka.headers`

Required:

- `key` (String) Header key.
- `value` (String) Header value.


<a id="nestedatt--kafka--random"></a>
### Nested Schema for `kafka.random`

Optional:

- `group_events` (Number) Number of events to group.


<a id="nestedatt--kafka--round_robin"></a>
### Nested Schema for `kafka.round_robin`

Optional:

- `group_events` (Number) Number of events to group.


<a id="nestedatt--kafka--sasl"></a>
### Nested Schema for `kafka.sasl`

Optional:

- `mechanism` (String) SASL mechanism.



<a id="nestedatt--ssl"></a>
### Nested Schema for `ssl`

Required:

- `certificate` (String) Client SSL certificate.
- `key` (String, Sensitive) Client SSL certificate key.

Optional:

- `certificate_authorities` (List of String) Server SSL certificate authorities.

## Import

Import is supported using the following syntax:

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
terraform import elasticstack_fleet_output.my_output <fleet_output_id>
```
