# Plan: data.elasticstack_fleet_output (Issue 684)

## Goals
- Implement the `elasticstack_fleet_output` data source to read a single Fleet output by ID.
- Align schema and state mapping with the existing Fleet output resource and the design in [dev-docs/terraform/data-sources/fleet/outputs.md](dev-docs/terraform/data-sources/fleet/outputs.md).
- Keep the data source experimental and not exposed by default per the design doc status.
- Support only `elasticsearch`, `logstash`, and `kafka` output types, with a clear error for any other discriminator.
- Provide comprehensive unit and acceptance tests with full attribute coverage.

## Scope and Assumptions
- The data source lives in `internal/fleet/output` to reuse the existing models and schema helpers.
- The generated `kbapi` client exposes `GET /api/fleet/outputs/{outputId}` and response unions for output types.
- The data source takes `output_id` (required) and `space_id` (optional) as inputs.
- The data source ID is a composite of `space_id` and `output_id` (match existing resource conventions).
- Experimental data sources are gated (for example, behind a provider feature flag or build tag) and not registered by default.

## Detailed Implementation Steps
1. **Inventory existing Fleet output code and client helpers**
   - Review `internal/fleet/output` models and schema to align computed attributes.
   - Confirm space-aware request editors used by existing Fleet resources in `internal/fleet/space_utils.go`.
   - Verify the kbapi client supports `GetOutput` for the Fleet outputs API.

2. **Add data source skeleton under `internal/fleet/output`**
   - Create a `data_source.go` with factory, `Metadata`, and `Configure` methods.
   - Add type assertions for `datasource.DataSource`, `datasource.DataSourceWithConfigure`.

3. **Define data source schema**
   - Add a `schema_data_source.go` (or extend `schema.go` with a dedicated schema builder).
   - Inputs:
     - `output_id`: required string.
     - `space_id`: optional string; keep null/unknown in plan.
   - Computed outputs per design doc:
     - `id`, `name`, `type`, `hosts`, `ca_sha256`, `ca_trusted_fingerprint`,
       `default_integrations`, `default_monitoring`, `config_yaml` (sensitive), `ssl`, `kafka`.
   - Reuse `outputModel` and existing custom types (for example, normalized JSON types) where relevant.

4. **Implement read logic**
   - Add `read_data_source.go` with `Read` that:
     - Builds a space-aware request editor from `space_id`.
     - Calls `fleet.GetOutput` with `output_id`.
     - Maps the response via `outputModel.populateFromAPI`.
     - Sets a composite ID derived from `space_id` and `output_id`.
     - Returns a clear diagnostic if the discriminator is unsupported.

5. **Model adjustments (if needed)**
   - If `outputModel.populateFromAPI` needs to accept a discriminator string or return a clearer error, update the model in `internal/fleet/output/models.go` and add table-driven unit tests.
   - Ensure null handling aligns with the design doc: empty SSL fields -> null; empty `ca_trusted_fingerprint` -> null; absent Kafka sub-objects -> null.

6. **Register data source behind an experimental gate**
  - Add the data source to provider registration only when the experimental gate is enabled.
  - Document the gate (for example, provider config flag or build tag) and ensure default behavior does not expose the data source.

7. **Documentation and examples**
   - Add an example under `examples/data-sources/elasticstack_fleet_output/`.
   - Run `make docs-generate` to produce docs under `docs/data-sources/`, this will use the default template for the new data source.

## Testing Plan (Thorough Coverage)
### Unit tests
- Add table-driven unit tests in `internal/fleet/output` to cover:
  - `populateFromAPI` mapping for `elasticsearch`, `logstash`, and `kafka` outputs.
  - Unsupported output discriminator returns a clear, non-panicking error.
  - Null/empty normalization rules for SSL and fingerprints.
- Use `require`/`assert` from `testify` and `t.Run` for case isolation.

### Acceptance tests
- Add acceptance tests to `internal/fleet/output/acc_test.go` that:
  - Create outputs (resource) for each supported type using existing `testdata` modules.
  - Read via the new data source using `output_id` and verify every computed attribute.
  - Include a space-aware read if the resource supports `space_id` (use a non-default space).
- Ensure acceptance tests account for the experimental gate (enable it explicitly for tests).
- Ensure each attribute appears in at least one acceptance test assertion.

### Test execution steps
- Unit tests:
  - `go test ./internal/fleet/output -run TestOutputModel` (and any other new unit tests).
- Acceptance tests (with required env vars):
  - `ELASTICSEARCH_ENDPOINTS=http://localhost:9200 ELASTICSEARCH_USERNAME=elastic ELASTICSEARCH_PASSWORD=password KIBANA_ENDPOINT=http://localhost:5601 TF_ACC=1 go test -v -run TestAccDataSourceFleetOutput ./internal/fleet/output`
  - If space-aware tests are added, include them in the same package run.
- Lint/docs:
  - `make docs-generate`
  - `make lint`

## Acceptance Test Coverage Checklist
- Elasticsearch output: `name`, `type`, `hosts`, `ssl`, `config_yaml`, `default_integrations`, `default_monitoring`, `ca_sha256`, `ca_trusted_fingerprint`.
- Logstash output: `name`, `type`, `hosts`, `ssl`, `config_yaml`, `default_integrations`, `default_monitoring`.
- Kafka output: `name`, `type`, `hosts`, `kafka` nested blocks, `ssl`, `config_yaml`.
- Space-aware read (if supported): verify `space_id` influences lookup.
- Unsupported type: unit test ensures a descriptive error is returned.

## Final Review Steps
1. **Critical code review**
  - Re-read all new/changed files with focus on correctness, error handling, and gate enforcement.
  - Verify schema matches the design doc and aligns with existing output resource semantics.

2. **Test review for critical path coverage**
  - Confirm that create/read flows for all supported output types are covered end-to-end.
  - Identify any missing assertions on computed fields (especially nested `ssl` and `kafka` blocks) and add tests.
  - Check that unsupported type handling is exercised and validated.

3. **UX review for schema and usage**
  - Validate input ergonomics (`output_id`, `space_id`) and the composite `id` behavior.
  - Ensure sensitive fields (`config_yaml`, `ssl.key`, `kafka.password`) are appropriately marked.
  - Look for opportunities to improve documentation or examples for clearer data source usage.
